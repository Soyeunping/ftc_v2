import streamlit as st
import json
import os
from law_data_collector import LawDataCollector
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ê³µì •ê±°ë˜ ë²•ë ¹ ë¶„ì„ ì‹œìŠ¤í…œ",
    page_icon="âš–ï¸",
    layout="wide"
)

# API í‚¤ ì„¤ì • í•¨ìˆ˜
def setup_api_key():
    """API í‚¤ë¥¼ ì•ˆì „í•˜ê²Œ ì„¤ì •"""
    # Streamlit Cloud Secretsì—ì„œ ê°€ì ¸ì˜¤ê¸° (ë°°í¬ìš©)
    try:
        if hasattr(st, 'secrets') and 'OPENAI_API_KEY' in st.secrets:
            os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]
            return True
    except:
        pass
    
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸° (ë¡œì»¬ìš©)
    if os.environ.get('OPENAI_API_KEY'):
        return True
    
    return False

# ì‚¬ì´ë“œë°”
st.sidebar.title("âš–ï¸ ê³µì •ê±°ë˜ ë²•ë ¹ ë¶„ì„")
st.sidebar.markdown("---")

# ë©”ì¸ ê¸°ëŠ¥ ì„ íƒ
page = st.sidebar.selectbox(
    "ê¸°ëŠ¥ ì„ íƒ",
    ["ğŸ  í™ˆ", "ğŸ“Š ë°ì´í„° ìˆ˜ì§‘", "ğŸ” ì¼€ì´ìŠ¤ ë¶„ì„", "ğŸ“‹ ë²•ë ¹ ìš”ì•½", "âš™ï¸ ì„¤ì •"]
)

class SimpleFairTradeRAG:
    """ê°„ë‹¨í•œ ë²•ë ¹ ë¶„ì„ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.vectorizer = TfidfVectorizer(max_features=1000, stop_words=None)
        self.documents = []
        self.doc_vectors = None
        
    def load_law_data(self, filename="fair_trade_laws.json"):
        """ë²•ë ¹ ë°ì´í„° ë¡œë“œ"""
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            return []
            
    def prepare_documents(self, laws):
        """ë²•ë ¹ì„ ê²€ìƒ‰ ê°€ëŠ¥í•œ ë¬¸ì„œë¡œ ë³€í™˜"""
        documents = []
        for law in laws:
            if law.get('content'):
                documents.append({
                    'text': f"{law['title']} {law['content']}",
                    'title': law['title'],
                    'type': 'full_law'
                })
            
            for article in law.get('articles', []):
                documents.append({
                    'text': f"{law['title']} ì œ{article['number']}ì¡° {article.get('title', '')} {article['content']}",
                    'title': f"{law['title']} ì œ{article['number']}ì¡°",
                    'type': 'article'
                })
        
        self.documents = documents
        if documents:
            texts = [doc['text'] for doc in documents]
            self.doc_vectors = self.vectorizer.fit_transform(texts)
        
        return len(documents)
    
    def search_relevant_documents(self, query, n_results=5):
        """ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰"""
        if not self.documents or self.doc_vectors is None:
            return []
            
        query_vector = self.vectorizer.transform([query])
        similarities = cosine_similarity(query_vector, self.doc_vectors).flatten()
        
        top_indices = similarities.argsort()[-n_results:][::-1]
        results = []
        
        for idx in top_indices:
            results.append({
                'text': self.documents[idx]['text'],
                'title': self.documents[idx]['title'],
                'similarity': similarities[idx]
            })
        
        return results
    
    def analyze_case_simple(self, case_description):
        """ê°„ë‹¨í•œ ì¼€ì´ìŠ¤ ë¶„ì„ (API ì—†ì´)"""
        relevant_docs = self.search_relevant_documents(case_description, n_results=3)
        
        if not relevant_docs:
            return "ê´€ë ¨ ë²•ë ¹ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•´ì£¼ì„¸ìš”."
        
        result = "## ğŸ“Š ê´€ë ¨ ë²•ë ¹ ë¶„ì„\n\n"
        
        for i, doc in enumerate(relevant_docs, 1):
            result += f"### {i}. {doc['title']}\n"
            result += f"**ìœ ì‚¬ë„:** {doc['similarity']:.3f}\n\n"
            result += f"**ë‚´ìš©:** {doc['text'][:300]}...\n\n"
            result += "---\n\n"
        
        result += "## ğŸ’¡ ë¶„ì„ ìš”ì•½\n\n"
        result += "ìœ„ì˜ ê´€ë ¨ ë²•ë ¹ë“¤ì„ ê²€í† í•˜ì—¬ ì¼€ì´ìŠ¤ì˜ ë²•ì  ìŸì ì„ íŒŒì•…í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n"
        result += "ë” ì •í™•í•œ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” OpenAI API í‚¤ë¥¼ ì„¤ì •í•˜ì—¬ AI ë¶„ì„ ê¸°ëŠ¥ì„ í™œìš©í•˜ì„¸ìš”."
        
        return result
    
    def analyze_case_ai(self, case_description):
        """AIë¥¼ í™œìš©í•œ ìƒì„¸ ì¼€ì´ìŠ¤ ë¶„ì„"""
        if not os.environ.get('OPENAI_API_KEY'):
            return self.analyze_case_simple(case_description)
        
        relevant_docs = self.search_relevant_documents(case_description, n_results=5)
        
        if not relevant_docs:
            return "ê´€ë ¨ ë²•ë ¹ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•´ì£¼ì„¸ìš”."
        
        context = "ê´€ë ¨ ë²•ë ¹:\n\n"
        for i, doc in enumerate(relevant_docs, 1):
            context += f"{i}. {doc['title']}\n{doc['text'][:400]}...\n\n"
        
        try:
            from openai import OpenAI
            client = OpenAI(api_key=os.environ.get('OPENAI_API_KEY'))
            
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ê³µì •ê±°ë˜ ì „ë¬¸ ë³€í˜¸ì‚¬ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì¼€ì´ìŠ¤ì™€ ê´€ë ¨ ë²•ë ¹ì„ ë°”íƒ•ìœ¼ë¡œ ë²•ì  ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”."},
                    {"role": "user", "content": f"ì¼€ì´ìŠ¤: {case_description}\n\n{context}\n\nìœ„ ì¼€ì´ìŠ¤ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”."}
                ],
                temperature=0.1
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\n\n" + self.analyze_case_simple(case_description)

def home_page():
    """í™ˆ í˜ì´ì§€"""
    st.title("ê³µì •ê±°ë˜ ë²•ë ¹ ë¶„ì„ ì‹œìŠ¤í…œ")
    st.markdown("---")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ¯ ì‹œìŠ¤í…œ ê°œìš”")
        st.markdown("""
        ì´ ì‹œìŠ¤í…œì€ ê³µì •ê±°ë˜ ê´€ë ¨ ë²•ë ¹ë“¤ì„ ë¶„ì„í•˜ì—¬ 
        ê¸°ì—…ì˜ ê³µì •ê±°ë˜ ì¼€ì´ìŠ¤ë¥¼ í‰ê°€í•˜ëŠ” AI ë„êµ¬ì…ë‹ˆë‹¤.
        
        **ì£¼ìš” ê¸°ëŠ¥:**
        - ğŸ“Š ë²•ë ¹ ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥
        - ğŸ” ì¼€ì´ìŠ¤ë³„ ë²•ì  ë¶„ì„
        - ğŸ“‹ ë²•ë ¹ ìš”ì•½ ë° ì„¤ëª…
        - âš–ï¸ ìœ„ë°˜ ê°€ëŠ¥ì„± í‰ê°€
        """)
    
    with col2:
        st.subheader("ğŸ“ˆ ì§€ì› ë²•ë ¹")
        st.markdown("""
        **í•µì‹¬ ë²•ë ¹:**
        - ê³µì •ê±°ë˜ë²•
        - í•˜ë„ê¸‰ë²•
        - ìƒìƒí˜‘ë ¥ë²•
        
        **ê´€ë ¨ ë²•ë ¹:**
        - ë…ì ê·œì œ ë° ê³µì •ê±°ë˜ì— ê´€í•œ ë²•ë¥ 
        - í•˜ë„ê¸‰ê±°ë˜ ê³µì •í™”ì— ê´€í•œ ë²•ë¥ 
        - ëŒ€Â·ì¤‘ì†Œê¸°ì—… ìƒìƒí˜‘ë ¥ ì´‰ì§„ì— ê´€í•œ ë²•ë¥ 
        """)
    
    st.markdown("---")
    
    # ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
    st.subheader("ğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ")
    
    # ë°ì´í„° íŒŒì¼ í™•ì¸
    if os.path.exists("fair_trade_laws.json"):
        with open("fair_trade_laws.json", 'r', encoding='utf-8') as f:
            laws = json.load(f)
        st.success(f"âœ… ë²•ë ¹ ë°ì´í„° ë¡œë“œë¨ ({len(laws)}ê°œ ë²•ë ¹)")
    else:
        st.warning("âš ï¸ ë²•ë ¹ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. 'ë°ì´í„° ìˆ˜ì§‘' í˜ì´ì§€ì—ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•´ì£¼ì„¸ìš”.")
    
    # API í‚¤ í™•ì¸
    if setup_api_key():
        st.success("âœ… OpenAI API í‚¤ ì„¤ì •ë¨ (AI ë¶„ì„ ê°€ëŠ¥)")
    else:
        st.info("ğŸ’¡ OpenAI API í‚¤ ë¯¸ì„¤ì • (ê¸°ë³¸ ë¶„ì„ë§Œ ê°€ëŠ¥)")

def data_collection_page():
    """ë°ì´í„° ìˆ˜ì§‘ í˜ì´ì§€"""
    st.title("ğŸ“Š ë²•ë ¹ ë°ì´í„° ìˆ˜ì§‘")
    st.markdown("---")
    
    st.markdown("""
    êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„°ì—ì„œ ê³µì •ê±°ë˜ ê´€ë ¨ ë²•ë ¹ë“¤ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    """)
    
    if st.button("ğŸš€ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘", type="primary"):
        with st.spinner("ë²•ë ¹ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            try:
                collector = LawDataCollector()
                laws = collector.collect_fair_trade_laws()
                
                if laws:
                    collector.save_laws_to_file(laws)
                    st.success(f"âœ… {len(laws)}ê°œì˜ ë²•ë ¹ì„ ì„±ê³µì ìœ¼ë¡œ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤!")
                    
                    # ìˆ˜ì§‘ëœ ë²•ë ¹ ëª©ë¡ í‘œì‹œ
                    st.subheader("ğŸ“‹ ìˆ˜ì§‘ëœ ë²•ë ¹ ëª©ë¡")
                    for i, law in enumerate(laws, 1):
                        with st.expander(f"{i}. {law['title']}"):
                            st.write(f"**í‚¤ì›Œë“œ:** {law.get('keyword', 'N/A')}")
                            st.write(f"**ì¡°ë¬¸ ìˆ˜:** {len(law.get('articles', []))}")
                            st.write(f"**URL:** {law.get('url', 'N/A')}")
                else:
                    st.error("âŒ ë°ì´í„° ìˆ˜ì§‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                    
            except Exception as e:
                st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

def case_analysis_page():
    """ì¼€ì´ìŠ¤ ë¶„ì„ í˜ì´ì§€"""
    st.title("ğŸ” ì¼€ì´ìŠ¤ ë¶„ì„")
    st.markdown("---")
    
    # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    if 'rag' not in st.session_state:
        st.session_state.rag = SimpleFairTradeRAG()
    
    rag = st.session_state.rag
    
    # ë²•ë ¹ ë°ì´í„° í™•ì¸ ë° ë¡œë“œ
    laws = rag.load_law_data()
    if not laws:
        st.warning("âš ï¸ ë²•ë ¹ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•´ì£¼ì„¸ìš”.")
        return
    
    # ë¬¸ì„œ ì¤€ë¹„
    if not rag.documents:
        with st.spinner("ë²•ë ¹ ë°ì´í„°ë¥¼ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            doc_count = rag.prepare_documents(laws)
            st.success(f"âœ… {doc_count}ê°œì˜ ë¬¸ì„œê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    st.markdown("---")
    
    # ë¶„ì„ ëª¨ë“œ ì„ íƒ
    analysis_mode = st.radio(
        "ë¶„ì„ ëª¨ë“œ ì„ íƒ:",
        ["ğŸ¤– AI ë¶„ì„ (OpenAI API í•„ìš”)", "ğŸ“ ê¸°ë³¸ ë¶„ì„ (API ë¶ˆí•„ìš”)"]
    )
    
    # ì¼€ì´ìŠ¤ ì…ë ¥
    st.subheader("ğŸ“ ì¼€ì´ìŠ¤ ì…ë ¥")
    
    # ì˜ˆì‹œ ì¼€ì´ìŠ¤ë“¤
    example_cases = {
        "í•˜ë„ê¸‰ ëŒ€ê¸ˆ ì‚­ê°": """
        Aê¸°ì—…ì€ ìë™ì°¨ ë¶€í’ˆ ì œì¡°ì—…ì²´ë¡œ, Bê¸°ì—…ìœ¼ë¡œë¶€í„° í•˜ë„ê¸‰ ì‘ì—…ì„ ë°›ì•„ì™”ìŠµë‹ˆë‹¤. 
        ìµœê·¼ Bê¸°ì—…ì´ ê°‘ìê¸° í•˜ë„ê¸‰ ëŒ€ê¸ˆì„ 30% ì‚­ê°í•˜ê² ë‹¤ê³  í†µë³´í–ˆê³ , 
        ê³„ì•½ì„œì—ëŠ” "ì›ì²­ì˜ ìš”ì²­ì— ë”°ë¼ ë‹¨ê°€ ì¡°ì • ê°€ëŠ¥"ì´ë¼ëŠ” ì¡°í•­ì´ ìˆìŠµë‹ˆë‹¤. 
        Aê¸°ì—…ì€ ì´ì— ë°˜ëŒ€í–ˆì§€ë§Œ Bê¸°ì—…ì€ "ê³„ì•½ì„œì— ëª…ì‹œë˜ì–´ ìˆë‹¤"ë©° ê°•í–‰í•˜ë ¤ê³  í•©ë‹ˆë‹¤.
        """,
        "ë…ì ì  ì§€ìœ„ ë‚¨ìš©": """
        ëŒ€ê¸°ì—… CëŠ” íŠ¹ì • ì‹œì¥ì—ì„œ 80% ì´ìƒì˜ ì ìœ ìœ¨ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. 
        ìµœê·¼ Cê¸°ì—…ì´ ì¤‘ì†Œê¸°ì—… Dì—ê²Œ "ìš°ë¦¬ ì œí’ˆë§Œ ì‚¬ìš©í•˜ë¼"ë©° 
        ë‹¤ë¥¸ ì—…ì²´ ì œí’ˆ ì‚¬ìš©ì„ ê¸ˆì§€í•˜ê³ , ì´ë¥¼ ì–´ê¸¸ ê²½ìš° ê±°ë˜ ì¤‘ë‹¨ì„ ìœ„í˜‘í•˜ê³  ìˆìŠµë‹ˆë‹¤.
        """,
        "ë¶ˆê³µì • ê±°ë˜ ì¡°ê±´": """
        ëŒ€ê¸°ì—… EëŠ” ì¤‘ì†Œê¸°ì—… Fì™€ ê±°ë˜í•˜ë©´ì„œ ë‹¤ìŒê³¼ ê°™ì€ ì¡°ê±´ì„ ì œì‹œí–ˆìŠµë‹ˆë‹¤:
        - 90ì¼ í›„ ì§€ê¸‰ ì¡°ê±´ (ê¸°ì¡´ 30ì¼ì—ì„œ ë³€ê²½)
        - í’ˆì§ˆ ë³´ì¦ê¸ˆ 20% ì˜ˆì¹˜ ìš”êµ¬
        - ê³„ì•½ í•´ì§€ ì‹œ 30ì¼ ì „ í†µë³´
        Fê¸°ì—…ì€ ì´ëŸ¬í•œ ì¡°ê±´ë“¤ì´ ë„ˆë¬´ ê¹Œë‹¤ë¡­ë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤.
        """
    }
    
    selected_example = st.selectbox(
        "ì˜ˆì‹œ ì¼€ì´ìŠ¤ ì„ íƒ (ì„ íƒì‚¬í•­):",
        ["ì§ì ‘ ì…ë ¥"] + list(example_cases.keys())
    )
    
    if selected_example != "ì§ì ‘ ì…ë ¥":
        case_description = st.text_area(
            "ì¼€ì´ìŠ¤ ì„¤ëª…:",
            value=example_cases[selected_example],
            height=200
        )
    else:
        case_description = st.text_area(
            "ì¼€ì´ìŠ¤ ì„¤ëª…:",
            placeholder="ë¶„ì„í•˜ê³  ì‹¶ì€ ê³µì •ê±°ë˜ ê´€ë ¨ ì¼€ì´ìŠ¤ë¥¼ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”...",
            height=200
        )
    
    if st.button("ğŸ” ë¶„ì„ ì‹œì‘", type="primary") and case_description.strip():
        with st.spinner("ì¼€ì´ìŠ¤ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            try:
                if "ğŸ¤– AI ë¶„ì„" in analysis_mode:
                    analysis_result = rag.analyze_case_ai(case_description)
                else:
                    analysis_result = rag.analyze_case_simple(case_description)
                
                st.subheader("ğŸ“Š ë¶„ì„ ê²°ê³¼")
                st.markdown(analysis_result)
                
                # ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
                st.download_button(
                    label="ğŸ“¥ ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ",
                    data=analysis_result,
                    file_name="ê³µì •ê±°ë˜_ì¼€ì´ìŠ¤_ë¶„ì„.txt",
                    mime="text/plain"
                )
                
            except Exception as e:
                st.error(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

def law_summary_page():
    """ë²•ë ¹ ìš”ì•½ í˜ì´ì§€"""
    st.title("ğŸ“‹ ë²•ë ¹ ìš”ì•½")
    st.markdown("---")
    
    if 'rag' not in st.session_state:
        st.session_state.rag = SimpleFairTradeRAG()
    
    rag = st.session_state.rag
    laws = rag.load_law_data()
    
    if not laws:
        st.warning("âš ï¸ ë²•ë ¹ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•´ì£¼ì„¸ìš”.")
        return
    
    # ë²•ë ¹ ëª©ë¡ í‘œì‹œ
    st.subheader("ğŸ“‹ ìˆ˜ì§‘ëœ ë²•ë ¹ ëª©ë¡")
    for i, law in enumerate(laws, 1):
        with st.expander(f"{i}. {law['title']}"):
            st.write(f"**í‚¤ì›Œë“œ:** {law.get('keyword', 'N/A')}")
            if law.get('content'):
                st.write(f"**ë‚´ìš©:** {law['content'][:500]}...")
            st.write(f"**ì¡°ë¬¸ ìˆ˜:** {len(law.get('articles', []))}")

def settings_page():
    """ì„¤ì • í˜ì´ì§€"""
    st.title("âš™ï¸ ì„¤ì •")
    st.markdown("---")
    
    st.subheader("ğŸ”‘ OpenAI API í‚¤ ì„¤ì •")
    
    # API í‚¤ ì…ë ¥
    api_key = st.text_input(
        "OpenAI API í‚¤:",
        type="password",
        help="OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”. AI ë¶„ì„ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ í•„ìš”í•©ë‹ˆë‹¤."
    )
    
    if api_key:
        os.environ["OPENAI_API_KEY"] = api_key
        st.success("âœ… API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
    elif setup_api_key():
        st.success("âœ… API í‚¤ê°€ ì´ë¯¸ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    else:
        st.info("ğŸ’¡ API í‚¤ê°€ ì—†ì–´ë„ ê¸°ë³¸ ë¶„ì„ ê¸°ëŠ¥ì€ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    
    st.markdown("---")
    
    st.subheader("ğŸ—‚ï¸ ë°ì´í„° ê´€ë¦¬")
    
    if st.button("ğŸ—‘ï¸ ë²•ë ¹ ë°ì´í„° ì‚­ì œ"):
        if os.path.exists("fair_trade_laws.json"):
            os.remove("fair_trade_laws.json")
            st.success("âœ… ë²•ë ¹ ë°ì´í„°ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
            # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
            if 'rag' in st.session_state:
                del st.session_state.rag
        else:
            st.warning("âš ï¸ ì‚­ì œí•  ë²•ë ¹ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    st.markdown("---")
    
    st.subheader("ğŸ“Š ì‹œìŠ¤í…œ ì •ë³´")
    
    # íŒŒì¼ ìƒíƒœ í™•ì¸
    if os.path.exists("fair_trade_laws.json"):
        file_size = os.path.getsize("fair_trade_laws.json") / 1024  # KB
        st.info(f"ğŸ“„ ë²•ë ¹ ë°ì´í„° íŒŒì¼: {file_size:.1f} KB")
    else:
        st.warning("ğŸ“„ ë²•ë ¹ ë°ì´í„° íŒŒì¼: ì—†ìŒ")

# í˜ì´ì§€ ë¼ìš°íŒ…
if page == "ğŸ  í™ˆ":
    home_page()
elif page == "ğŸ“Š ë°ì´í„° ìˆ˜ì§‘":
    data_collection_page()
elif page == "ğŸ” ì¼€ì´ìŠ¤ ë¶„ì„":
    case_analysis_page()
elif page == "ğŸ“‹ ë²•ë ¹ ìš”ì•½":
    law_summary_page()
elif page == "âš™ï¸ ì„¤ì •":
    settings_page()